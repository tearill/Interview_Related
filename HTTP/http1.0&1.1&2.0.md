# HTTP 1.0/1.1/2.0  

## HTTP 1.0 和 HTTP 1.1 的一些区别  
1. **缓存**处理  
  1.0 主要采取 Expire、If-Modify-Since  
  1.1 引入了 etag/If-None-Match  
2. **带宽优化**及网络连接的使用  
  1.0 存在浪费带宽，比如客户端只需要某个对象的某些部分，但服务器将整个对象传输过来  
  1.1 在头部增加了 Content-range 字段，允许只请求资源的某个部分(状态码 206)  
3. **错误通知**的管理  
  1.1 新增 24 个错误状态响应码  
4. **Host 头**处理  
  1.0 中认为每台服务器都绑定一个唯一的 IP 地址，URL 中不传主机名  
  但现在虚拟主机技术发展，一台物理服务器可以存在多个虚拟主机共享一个 IP  
  1.1 的请求消息和响应消息都支持 HOST 头域，如果没有会报错(状态码 400)  
5. **长连接**  
  1.1 中默认开启 Connection: keep-alive，一定程度上弥补了 1.0 每次请求都要创建连接的缺点  

## HTTP 1.1 如何解决 HTTP 的队头阻塞问题？  
HTTP 队头阻塞的根本原因在于 HTTP 基于请求-响应的模型，在同一个 TCP 长连接中，因为处理的太慢耽误了时间，前面的请求没有得到响应，后面的请求就会被阻塞，由于“请求-应答”模式不能改变，所以对头阻塞问题在 HTTP1.1 中无法解决，只能缓解  

- 比如：用打卡机来做比喻，上班的时间点上，大家都在排队打卡，可这个时候偏偏最前面的那个人遇到了打卡机故障，怎么也不能打卡成功，急得满头大汗。等找人把打卡机修好，后面排队的所有人全迟到了  

1. 并发连接：对于一个域名允许分配多个长连接，那么相当于增加了任务队列，不至于一个队伍的任务阻塞其它所有任务，用数量来解决质量问题  
  举例：公司里可以再多买几台打卡机放在前台，这样大家可以不用挤在一个队伍里，分散打卡，一个队伍偶尔阻塞也不要紧，可以改换到其他不阻塞的队伍  
2. 域名分片：分出二级域名，指向同一台服务器，使得能够并发的连接数增加了  
  举例：多开几个打卡的地方，每个楼层、办公区的入口也放上三四台打卡机，把人进一步分流，不要都往前台挤  

> 并发连接存在的问题：如果每个客户端都想自己快，建立很多个连接，用户数 × 并发数就会是个天文数字。服务器的资源根本就扛不住，或者被服务器认为是恶意攻击，反而会造成“拒绝服务”(DDOS)，所以 HTTP RFC2616 中限制每个客户端最多并发 2 个连接，但实际上这个数字太小了，众多浏览器都无视标准，例如 Chrome 最大建立 6 个连接，RFC7230 取消了这个限制  

## HTTP2 有哪些改进？  
- 头部压缩  
  尤其对于 GET 请求，请求报文几乎全是请求头，HTTP2 针对头部字段，采用了 HPACK 的压缩算法对请求头进行压缩  

- 多路复用  
  HTTP 1.1 使用并发连接和域名分片的方式解决队头阻塞，但并没有从 HTTP 本身的层面解决这个问题，只是增加了 TCP 连接，分摊风险，多条 TCP 连接会竞争有限的带宽，让真正优先级高的请求不能优先处理  

  **HTTP 2.0 从 HTTP 协议本身解决了 HTTP 队头阻塞**  
  ***二进制分帧***  
    HTTP2 把报文全部换成二进制格式，方便机器的解析  
    Headers 帧存放头部字段，Data 帧存放请求体数据，分帧后服务器看到的是一堆乱序的二进制帧，不存在先后顺序，也不会排队等待，也就没有了 HTTP 队头阻塞的问题  
    通信双方都可以给对方发送二进制帧，这种二进制帧的双向传输的序列，也叫做流(Stream)。HTTP/2 用流来在一个 TCP 连接上来进行多个数据帧的通信，这就是多路复用的概念

- 服务器推送  
  在 HTTP/2 当中，服务器已经不再是完全被动地接收请求，响应请求  
  服务器也能新建 stream 给客户端发消息，当 TCP 连接建立之后，比如浏览器请求一个 HTML 文件，服务器就可以在返回 HTML 的基础上，将 HTML 中引用到的其他资源文件一起返回给客户端，减少客户端的等待  
